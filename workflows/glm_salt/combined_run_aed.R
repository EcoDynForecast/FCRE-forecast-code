library(tidyverse)
library(lubridate)
set.seed(100)

options(future.globals.maxSize= 891289600)

Sys.setenv("AWS_DEFAULT_REGION" = "s3",
           "AWS_S3_ENDPOINT" = "flare-forecast.org")

lake_directory <- here::here()

starting_index <- 1

files.sources <- list.files(file.path(lake_directory, "R"), full.names = TRUE)
sapply(files.sources, source)

sim_names <- "salt_oxy"
config_set_name <- "glm_salt"
configure_run_file <- "configure_run.yml"


num_forecasts <- 1 #52 * 3 - 3
#num_forecasts <- 1#19 * 7 + 1
days_between_forecasts <- 7
forecast_horizon <- 16 #32
starting_date <- as_date("2020-09-25")
#second_date <- as_date("2020-12-01") - days(days_between_forecasts)
#starting_date <- as_date("2018-07-20")
#second_date <- as_date("2019-01-01") - days(days_between_forecasts)
#second_date <- as_date("2020-12-31") #- days(days_between_forecasts)
second_date <- as_date("2020-09-30") #- days(days_between_forecasts)



start_dates <- rep(NA, num_forecasts)
start_dates[1:2] <- c(starting_date, second_date)
for(i in 3:(3 + num_forecasts)){
  start_dates[i] <- as_date(start_dates[i-1]) + days(days_between_forecasts)
}

start_dates <- as_date(start_dates)
forecast_start_dates <- start_dates + days(days_between_forecasts)
forecast_start_dates <- forecast_start_dates[-1]

print(start_dates)
print(forecast_start_dates)
j = 1
sites <- "fcre"

#function(i, sites, lake_directory, sim_names, config_files, )

message(paste0("Running site: ", sites[j]))

if(starting_index == 1){
  run_config <- yaml::read_yaml(file.path(lake_directory, "configuration", config_set_name, configure_run_file))
  run_config$configure_flare <- "configure_flare.yml"
  run_config$sim_name <- sim_names
  yaml::write_yaml(run_config, file = file.path(lake_directory, "configuration", config_set_name, configure_run_file))
  if(file.exists(file.path(lake_directory, "restart", sites[j], sim_names, configure_run_file))){
    unlink(file.path(lake_directory, "restart", sites[j], sim_names, configure_run_file))
  }
}

use_s3 <- TRUE

##'
# Set up configurations for the data processing
config_obs <- FLAREr::initialize_obs_processing(lake_directory, observation_yml = "observation_processing.yml", config_set_name = config_set_name)
config <- FLAREr::set_configuration(configure_run_file,lake_directory, config_set_name = config_set_name)

#' Clone or pull from data repositories

FLAREr::get_git_repo(lake_directory,
                     directory = config_obs$realtime_insitu_location,
                     git_repo = "https://github.com/FLARE-forecast/FCRE-data.git")

FLAREr::get_git_repo(lake_directory,
                     directory = config_obs$realtime_met_station_location,
                     git_repo = "https://github.com/FLARE-forecast/FCRE-data.git")

FLAREr::get_git_repo(lake_directory,
                     directory = config_obs$realtime_inflow_data_location,
                     git_repo = "https://github.com/FLARE-forecast/FCRE-data.git")

#get_git_repo(lake_directory,
#             directory = config_obs$manual_data_location,
#             git_repo = "https://github.com/FLARE-forecast/FCRE-data.git")

#' Download files from EDI

FLAREr::get_edi_file(edi_https = "https://pasta.lternet.edu/package/data/eml/edi/389/6/a5524c686e2154ec0fd0459d46a7d1eb",
                     file = config_obs$met_raw_obs_fname[2],
                     lake_directory)

FLAREr::get_edi_file(edi_https = "https://pasta.lternet.edu/package/data/eml/edi/271/6/23a191c1870a5b18cbc17f2779f719cf",
                     file = config_obs$insitu_obs_fname[2],
                     lake_directory)

FLAREr::get_edi_file(edi_https = "https://pasta.lternet.edu/package/data/eml/edi/198/8/336d0a27c4ae396a75f4c07c01652985",
                     file = config_obs$secchi_fname,
                     lake_directory)

FLAREr::get_edi_file(edi_https = "https://pasta.lternet.edu/package/data/eml/edi/200/11/d771f5e9956304424c3bc0a39298a5ce",
                     file = config_obs$ctd_fname,
                     lake_directory)

FLAREr::get_edi_file(edi_https = "https://pasta.lternet.edu/package/data/eml/edi/199/8/da174082a3d924e989d3151924f9ef98",
                     file = config_obs$nutrients_fname,
                     lake_directory)


FLAREr::get_edi_file(edi_https = "https://pasta.lternet.edu/package/data/eml/edi/202/7/f5fa5de4b49bae8373f6e7c1773b026e",
                     file = config_obs$inflow_raw_file1[2],
                     lake_directory)

FLAREr::get_edi_file(edi_https = "https://pasta.lternet.edu/package/data/eml/edi/542/1/791ec9ca0f1cb9361fa6a03fae8dfc95",
                     file = "silica_master_df.csv",
                     lake_directory)

FLAREr::get_edi_file(edi_https = "https://pasta.lternet.edu/package/data/eml/edi/551/5/38d72673295864956cccd6bbba99a1a3",
                     file = "Dissolved_CO2_CH4_Virginia_Reservoirs.csv",
                     lake_directory)


#' Clean up observed meterology

cleaned_met_file <- met_qaqc_csv(realtime_file = file.path(config_obs$file_path$data_directory, config_obs$met_raw_obs_fname[1]),
                                 qaqc_file = file.path(config_obs$file_path$data_directory, config_obs$met_raw_obs_fname[2]),
                                 cleaned_met_file = file.path(config_obs$file_path$targets_directory, config_obs$site_id,paste0("observed-met_",config_obs$site_id,".csv")),
                                 input_file_tz = "EST",
                                 nldas = NULL,
                                 site_id = config_obs$site_id)

#' Clean up observed inflow

cleaned_inflow_file <- inflow_qaqc_csv(realtime_file = file.path(config_obs$file_path$data_directory, config_obs$inflow_raw_file1[1]),
                                       qaqc_file = file.path(config_obs$file_path$data_directory, config_obs$inflow_raw_file1[2]),
                                       nutrients_file = file.path(config_obs$file_path$data_directory, config_obs$nutrients_fname),
                                       silica_file = file.path(config_obs$file_path$data_directory,  config_obs$silica_fname),
                                       co2_ch4 = file.path(config_obs$file_path$data_directory, config_obs$ch4_fname),
                                       cleaned_inflow_file = file.path(config_obs$file_path$targets_directory, config_obs$site_id, paste0(config_obs$site_id,"-targets-inflow.csv")),
                                       input_file_tz = 'EST',
                                       site_id = config_obs$site_id)

#' Clean up observed insitu measurements

cleaned_insitu_file <- in_situ_qaqc_csv(insitu_obs_fname = file.path(config_obs$file_path$data_directory,config_obs$insitu_obs_fname),
                                        data_location = config_obs$file_path$data_directory,
                                        maintenance_file = file.path(config_obs$file_path$data_directory,config_obs$maintenance_file),
                                        ctd_fname = file.path(config_obs$file_path$data_directory, config_obs$ctd_fname),
                                        nutrients_fname =  file.path(config_obs$file_path$data_directory, config_obs$nutrients_fname),
                                        secchi_fname = file.path(config_obs$file_path$data_directory, config_obs$secchi_fname),
                                        ch4_fname = file.path(config_obs$file_path$data_directory, config_obs$ch4_fname),
                                        cleaned_insitu_file = file.path(config_obs$file_path$targets_directory, config_obs$site_id, paste0(config_obs$site_id,"-targets-insitu.csv")),
                                        lake_name_code = config_obs$site_id,
                                        config = config_obs)

FLAREr::put_targets(site_id = config$location$site_id,
                    cleaned_insitu_file = cleaned_insitu_file,
                    cleaned_met_file = cleaned_met_file,
                    cleaned_inflow_file = cleaned_inflow_file,
                    use_s3 = use_s3,
                    config = config)

##` Download NOAA forecasts`

message("    Downloading NOAA data")

cycle <- "00"

#for(i in 1:length(forecast_start_dates)){
#  noaa_forecast_path <- file.path(config$met$forecast_met_model, config$location$site_id, forecast_start_dates[i], "00")
#  if(length(list.files(file.path(lake_directory,"drivers", noaa_forecast_path))) == 0){
#    FLAREr::get_driver_forecast(lake_directory, forecast_path = noaa_forecast_path, config)
#  }
#}

available_dates <- list.files(file.path(lake_directory,"drivers","noaa","NOAAGEFS_1hr","fcre"))

if(starting_index == 1){
  config$run_config$start_datetime <- as.character(paste0(start_dates[1], " 00:00:00"))
  config$run_config$forecast_start_datetime <- as.character(paste0(start_dates[2], " 00:00:00"))
  config$run_config$forecast_horizon <- 0
  config$run_config$restart_file <- NA
  run_config <- config$run_config
  yaml::write_yaml(run_config, file = file.path(config$file_path$configuration_directory, configure_run_file))
}

#for(i in 1:1){

for(i in starting_index:length(forecast_start_dates)){
  #i <- 1

  https_file <- "https://raw.githubusercontent.com/cayelan/FCR-GLM-AED-Forecasting/master/FCR_2013_2019GLMHistoricalRun_GLMv3beta/inputs/FCR_SSS_inflow_2013_2021_20211102_allfractions_2DOCpools.csv"
  if(!file.exists(file.path(config$file_path$execute_directory, basename(https_file)))){
    download.file(https_file,
                  file.path(config$file_path$execute_directory, basename(https_file)))
  }


  config <- FLAREr::set_configuration(configure_run_file, lake_directory, config_set_name = config_set_name)

  num_dates_skipped <- 1
  if(i != 1){
    while(!lubridate::as_date(config$run_config$forecast_start_datetime) %in% lubridate::as_date(available_dates) & i <= length(forecast_start_dates)){
      FLAREr::update_run_config(config, lake_directory, configure_run_file, saved_file = NA, new_horizon = forecast_horizon, day_advance = num_dates_skipped * days_between_forecasts, new_start_datetime = FALSE)
      config <- FLAREr::set_configuration(configure_run_file, lake_directory, config_set_name = config_set_name)
      num_dates_skipped <- num_dates_skipped + 1
      i <- i + 1
    }
  }

  config <- FLAREr::set_configuration(configure_run_file,lake_directory, config_set_name = config_set_name)
  config <- FLAREr::get_restart_file(config, lake_directory)

  message(paste0("     Running forecast that starts on: ", config$run_config$start_datetime))

  if(config$run_config$forecast_horizon > 0){

    config$future_inflow_flow_coeff <- c(0.0010803, 0.9478724, 0.3478991)
    config$future_inflow_flow_error <- 0.00965
    config$future_inflow_temp_coeff <- c(0.20291, 0.94214, 0.04278)
    config$future_inflow_temp_error <- 0.943

    inflow_forecast_path <- FLAREr::get_driver_forecast_path(config,
                                                             forecast_model = config$inflow$forecast_inflow_model)

    temp_flow_forecast <- forecast_inflows_outflows_arrow(inflow_obs = file.path(config$file_path$qaqc_data_directory, "fcre-targets-inflow.csv"),
                                                          inflow_forecast_path = inflow_forecast_path,
                                                          obs_met_file = file.path(config$file_path$qaqc_data_directory,"observed-met_fcre.csv"),
                                                          output_dir = config$file_path$inflow_directory,
                                                          inflow_model = config$inflow$forecast_inflow_model,
                                                          inflow_process_uncertainty = FALSE,
                                                          forecast_location = config$file_path$forecast_output_directory,
                                                          config = config,
                                                          use_s3 = use_s3,
                                                          met_bucket = config$s3$drivers$bucket,
                                                          met_endpoint = config$s3$drivers$endpoint,
                                                          inflow_bucket = config$s3$inflow_drivers$bucket,
                                                          inflow_endpoint = config$s3$inflow_drivers$endpoint,
                                                          model_name = "glm",
                                                          forecast_date = lubridate::as_date(config$run_config$start_datetime),
                                                          forecast_hour = 0)
  }

  #Need to remove the 00 ensemble member because it only goes 16-days in the future

  #pars_config <- NULL #readr::read_csv(file.path(config$file_path$configuration_directory, "FLAREr", config$model_settings$par_config_file), col_types = readr::cols())
  pars_config <- readr::read_csv(file.path(config$file_path$configuration_directory, config$model_settings$par_config_file), col_types = readr::cols())
  obs_config <- readr::read_csv(file.path(config$file_path$configuration_directory, config$model_settings$obs_config_file), col_types = readr::cols())
  states_config <- readr::read_csv(file.path(config$file_path$configuration_directory, config$model_settings$states_config_file), col_types = readr::cols())


  #Download and process observations (already done)

  met_out <- FLAREr::generate_glm_met_files_arrow(obs_met_file = file.path(config$file_path$qaqc_data_directory, paste0("observed-met_",config$location$site_id,".csv")),
                                          out_dir = config$file_path$execute_directory,
                                          forecast_dir = forecast_dir,
                                          config = config,
                                          use_s3 = use_s3,
                                          bucket = config$s3$drivers$bucket,
                                          endpoint = config$s3$drivers$endpoint)

  inflow_forecast_path <- FLAREr::get_driver_forecast_path(config,
                                                           forecast_model = config$inflow$forecast_inflow_model)

  inflow_outflow_files <- FLAREr::create_glm_inflow_outflow_files_arrow(inflow_file_dir = inflow_forecast_path,
                                                                        inflow_obs = file.path(config$file_path$qaqc_data_directory, paste0(config$location$site_id, "-targets-inflow.csv")),
                                                                        working_directory = config$file_path$execute_directory,
                                                                        config = config,
                                                                        state_names = states_config$state_names,
                                                                        use_s3 = use_s3,
                                                                        bucket = config$s3$inflow_drivers$bucket,
                                                                        endpoint = config$s3$inflow_drivers$endpoint)

  management <- NULL

  if(config$model_settings$model_name == "glm_aed"){

    inflow_outflow_files$inflow_file_name <- cbind(inflow_outflow_files$inflow_file_name, rep(file.path(config$file_path$execute_directory,basename(https_file)), length(inflow_outflow_files$inflow_file_name)))
  }

  #Create observation matrix
  obs <- FLAREr::create_obs_matrix(cleaned_observations_file_long = file.path(config$file_path$qaqc_data_directory,paste0(config$location$site_id, "-targets-insitu.csv")),
                                   obs_config = obs_config,
                                   config)

  start_datetime <- lubridate::as_datetime(config$run_config$start_datetime)
  if(is.na(config$run_config$forecast_start_datetime)){
    end_datetime <- lubridate::as_datetime(config$run_config$end_datetime)
    forecast_start_datetime <- end_datetime
  }else{
    forecast_start_datetime <- lubridate::as_datetime(config$run_config$forecast_start_datetime)
    end_datetime <- forecast_start_datetime + lubridate::days(config$run_config$forecast_horizon)
  }

  full_time <- seq(start_datetime, end_datetime, by = "1 day")

  obs_secchi <- readr::read_csv(file.path(config$file_path$qaqc_data_directory,paste0(config$location$site_id, "-targets-insitu.csv")), show_col_types = FALSE) %>%
    dplyr::filter(variable == "secchi") %>%
    dplyr::mutate(date = lubridate::as_date(datetime)) %>%
    dplyr::right_join(tibble::tibble(date = lubridate::as_datetime(full_time)), by = "date") %>%
    dplyr::mutate(observation = ifelse(date > lubridate::as_date(forecast_start_datetime), NA, observation)) %>%
    dplyr::arrange(date) %>%
    dplyr::select(observation) %>%
    as_vector()

  obs_depth <- readr::read_csv(file.path(config$file_path$qaqc_data_directory,paste0(config$location$site_id, "-targets-insitu.csv")), show_col_types = FALSE) %>%
    dplyr::filter(variable == "depth") %>%
    dplyr::mutate(date = lubridate::as_date(datetime),
                  hour = hour(datetime)) %>%
    dplyr::filter(hour == 0)  %>%
    dplyr::right_join(tibble::tibble(date = lubridate::as_datetime(full_time)), by = "date") %>%
    dplyr::mutate(observation = ifelse(date > lubridate::as_date(forecast_start_datetime), NA, observation)) %>%
    dplyr::arrange(date) %>%
    dplyr::select(observation) %>%
    as_vector()


  #obs[ ,2:dim(obs)[2], ] <- NA

  states_config <- FLAREr::generate_states_to_obs_mapping(states_config, obs_config)

  model_sd <- FLAREr::initiate_model_error(config, states_config)

  init <- FLAREr::generate_initial_conditions(states_config,
                                              obs_config,
                                              pars_config,
                                              obs,
                                              config,
                                              historical_met_error = met_out$historical_met_error)
  #Run EnKF
  da_forecast_output <- FLAREr::run_da_forecast(states_init = init$states,
                                                #                                            da_forecast_output <- run_da_forecast(states_init = init$states,
                                                pars_init = init$pars,
                                                aux_states_init = init$aux_states_init,
                                                obs = obs,
                                                obs_sd = obs_config$obs_sd,
                                                model_sd = model_sd,
                                                working_directory = config$file_path$execute_directory,
                                                met_file_names = met_out$filenames,
                                                inflow_file_names = inflow_outflow_files$inflow_file_name,
                                                outflow_file_names = inflow_outflow_files$outflow_file_name,
                                                config = config,
                                                pars_config = pars_config,
                                                states_config = states_config,
                                                obs_config = obs_config,
                                                management,
                                                da_method = config$da_setup$da_method,
                                                par_fit_method = config$da_setup$par_fit_method,
                                                obs_secchi = obs_secchi,
                                                obs_depth = obs_depth)

  # Save forecast

  saved_file <- FLAREr::write_forecast_netcdf(da_forecast_output = da_forecast_output,
                                              forecast_output_directory = config$file_path$forecast_output_directory,
                                              use_short_filename = TRUE)

  forecast_df <- FLAREr::write_forecast_arrow(da_forecast_output = da_forecast_output,
                                              use_s3 = use_s3,
                                              bucket = config$s3$forecasts_parquet$bucket,
                                              endpoint = config$s3$forecasts_parquet$endpoint)


  FLAREr::generate_forecast_score_arrow(targets_file = file.path(config$file_path$qaqc_data_directory,paste0(config$location$site_id, "-targets-insitu.csv")),
                                        forecast_df = forecast_df,
                                        use_s3 = use_s3,
                                        bucket = config$s3$scores$bucket,
                                        endpoint = config$s3$scores$endpoint)

  #rm(da_forecast_output)
  #gc()
  message("Generating plot")
  FLAREr::plotting_general_2(file_name = saved_file,
                             target_file = file.path(config$file_path$qaqc_data_directory, paste0(config$location$site_id, "-targets-insitu.csv")),
                             ncore = 2,
                             obs_csv = FALSE)

  FLAREr::put_forecast(saved_file, eml_file_name = NULL, config)

  new_time <- as.character(lubridate::as_datetime(config$run_config$forecast_start_datetime) +
                             lubridate::days(days_between_forecasts))

  FLAREr::update_run_config(config, lake_directory, configure_run_file, saved_file, new_horizon = forecast_horizon, day_advance = days_between_forecasts)
}
